{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hackathon_Notebook.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[
  {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github//ML4SCI/ML4SCIHackathon/blob/main/GravitationalLensingChallenge/StrongLensingChallenge-Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
  {"cell_type":"markdown","metadata":{"id":"9c5_HHutGM75"},"source":["# Strong Lensing Challenge - Multi-Class Classification \n","\n","Gravitational lensing has been a cornerstone in many cosmology experiments and studies since it was discussed in Einsteinâ€™s calculations back in 1936 and discovered in 1979, and one area of particular interest is the study of dark matter via substructure in strong lensing images. In this challenge, we focus on exploring the potential of supervised models in identifying dark matter based on simulated strong lensing images with different substructure.\n","\n","This is an example notebook for the Multi-Class Classification Challenge. In this notebook, we demonstrate a simple CNN model implemented using the PyTorch library to solve the task of multi-class classification of strong lensing images.\n","\n","### Dataset\n","\n","The Dataset consists of three classes, strong lensing images with no substructure, spherical substructure, and vortex substructure. The images have been normalized using min-max normalization, but you are free to use any normalization or data augmentation methods to improve your results.\n","\n","Link to the Dataset: https://drive.google.com/file/d/1B_UZtU4W65ZViTJsLeFfvK-xXCYUhw2A/view?usp=sharing\n","\n","### Evaluation Metrics\n","\n","* ROC curve (Receiver Operating Characteristic curve) and AUC score (Area Under the ROC Curve)   \n","\n","The model performance will be tested on the hidden test dataset based on the above metrics.\n","\n","### Instructions for using the notebook\n","\n","1. Use GPU acceleration: (Edit --> Notebook settings --> Hardware accelerator --> GPU)\n","2. Run the cells: (Runtime --> Run all)"]},{"cell_type":"code","metadata":{"id":"lIiqNE2UGLev"},"source":["# Download Dataset\n","!gdown http://drive.google.com/uc?id=1B_UZtU4W65ZViTJsLeFfvK-xXCYUhw2A\n","!unzip -q dataset.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tPMhi3uvHTBK"},"source":["## Multi-Class Classification using a Supervised Model"]},{"cell_type":"markdown","metadata":{"id":"513RtRF4Hf3Z"},"source":["### 1. Data Visualization and Preprocessing "]},{"cell_type":"markdown","metadata":{"id":"WR-nMgqoIary"},"source":["#### 1.1 Import all the necessary libraries"]},{"cell_type":"code","metadata":{"id":"agXdpFwPPiHw","cellView":"both"},"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torchvision import models\n","from tqdm.notebook import tqdm\n","from sklearn.metrics import roc_auc_score, roc_curve, auc\n","from sklearn.preprocessing import label_binarize\n","import torch.utils.data as data\n","from scipy import interp\n","from itertools import cycle\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Mw4NndbHsiY"},"source":["#### 1.2 Preview the Data"]},{"cell_type":"code","metadata":{"id":"U0m86HY9DJSl"},"source":["# Define the input paths\n","train_path1 = './dataset/train/no'\n","train_files1 = [os.path.join(train_path1, f) for f in os.listdir(train_path1) if f.endswith(\".npy\")]\n","train_path2 = './dataset/train/sphere'\n","train_files2 = [os.path.join(train_path2, f) for f in os.listdir(train_path2) if f.endswith(\".npy\")]\n","train_path3 = './dataset/train/vort'\n","train_files3 = [os.path.join(train_path3, f) for f in os.listdir(train_path3) if f.endswith(\".npy\")]\n","\n","# Number of samples to display per class\n","n = 5\n","\n","# Plot the samples \n","i = 1\n","print('Samples with no substructure: ')\n","plt.rcParams['figure.figsize'] = [14, 14]\n","for image in train_files1[:n]:\n","    ax = plt.subplot(3,n,i)\n","    plt.imshow(np.load(image).reshape(150,150), cmap='gray')\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    i += 1\n","plt.show()\n","\n","print('Samples with spherical substructure: ')\n","plt.rcParams['figure.figsize'] = [14, 14]\n","for image in train_files2[:n]:\n","    ax = plt.subplot(3,n,i)\n","    plt.imshow(np.load(image).reshape(150,150), cmap='gray')\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    i += 1\n","plt.show()\n","\n","print('Samples with vortex substructure: ')\n","plt.rcParams['figure.figsize'] = [14, 14]\n","for image in train_files3[:n]:\n","    ax = plt.subplot(3,n,i)\n","    plt.imshow(np.load(image).reshape(150,150), cmap='gray')\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    i += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RYWK0ZkMIMSr"},"source":["#### 1.3 Import Training and Validation Data"]},{"cell_type":"code","metadata":{"id":"2yrkV-fO9mWI"},"source":["# Set Batch Size\n","batch_size = 100\n","\n","# Define Data Loaders\n","def npy_loader(path):\n","    sample = torch.from_numpy(np.load(path))\n","    return sample\n","    \n","train_data = torchvision.datasets.DatasetFolder(root='./dataset/train', loader=npy_loader, extensions='.npy')\n","print(\"Training Classes: \" + str(train_data.class_to_idx))\n","train_data_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n","val_data = torchvision.datasets.DatasetFolder(root='./dataset/val', loader=npy_loader, extensions='.npy')\n","print(\"Validation Classes: \" + str(val_data.class_to_idx))\n","val_data_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ABBx_F7oI_vC"},"source":["### 2. Training"]},{"cell_type":"markdown","metadata":{"id":"clDeWqesKU_8"},"source":["#### 2.1 Defining a CNN Model\n","\n","You may refer to this [article](https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148) to learn about Convolutional Neural Networks (CNN)"]},{"cell_type":"code","metadata":{"id":"qlDjFP-mraJG"},"source":["# Define the Model\n","class CNN(nn.Module):\n","  def __init__(self):\n","    super(CNN, self).__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = 5, stride = 2, padding = 0)\n","    self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 5, stride = 2, padding = 0)\n","    self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = 5, stride = 2, padding = 0)\n","    self.linear1 = nn.Linear(480, 84)\n","    self.linear2 = nn.Linear(84, 3)\n","    self.tanh = nn.Tanh()\n","    self.avgpool = nn.AvgPool2d(kernel_size = 2, stride = 2)\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = self.tanh(x)\n","    x = self.avgpool(x)\n","    x = self.conv2(x)\n","    x = self.tanh(x)\n","    x = self.avgpool(x)\n","    x = self.conv3(x)\n","    x = self.tanh(x)\n","    x = x.reshape(x.shape[0], -1)\n","    x = self.linear1(x)\n","    x = self.tanh(x)\n","    x = self.linear2(x)\n","    return x\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = CNN().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Ixy2T3PKpes"},"source":["#### 2.2 Training the CNN Model"]},{"cell_type":"code","metadata":{"id":"0dsVNm2J7K67"},"source":["# Loss Function\n","criteria = nn.CrossEntropyLoss()\n","\n","# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","\n","# Calculate the number of batches\n","n_batches_train = (len(train_files1)*3)/batch_size\n","\n","# Train the model\n","n_epochs = 50 # Number of Training Epochs\n","loss_array = []\n","pbar = tqdm(range(1, n_epochs+1))\n","for epoch in pbar:\n","    train_loss = 0.0\n","    train_acc = 0.0\n","    \n","    for step, (x_tr, y_tr) in enumerate(train_data_loader):\n","\n","        data = Variable(x_tr).type(torch.cuda.FloatTensor)\n","        if torch.cuda.is_available():\n","          data = data.cuda()\n","        labels = torch.tensor(y_tr, dtype=torch.long, device=device)\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","        _, preds = torch.max(model(data).data, 1)\n","        correct = (preds == labels).float().sum()\n","        loss = criteria(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss\n","        train_acc += correct/data.shape[0]\n","\n","    train_loss = train_loss/n_batches_train\n","    train_acc = train_acc/n_batches_train\n","    # Display the Training Stats\n","    pbar.set_postfix({ 'Training Loss': train_loss.item(), 'Training Acc': train_acc.item() })"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s73f62tkLopN"},"source":["### 3. Testing"]},{"cell_type":"markdown","metadata":{"id":"YPIMrzmAMpsv"},"source":["#### 3.1 Testing the CNN Model on Validation Data"]},{"cell_type":"code","metadata":{"id":"emtSHxk6xsOG"},"source":["y_score = []\n","y_test = []\n","for _, (x_ts, y_ts) in enumerate(val_data_loader):\n","\n","    mini_val_data = Variable(x_ts).type(torch.cuda.FloatTensor)\n","    if torch.cuda.is_available():\n","      mini_val_data = mini_val_data.cuda()\n","    y_score.append(torch.nn.functional.softmax(model(mini_val_data), dim=1).cpu().detach().numpy())\n","    y_test.append(y_ts.cpu().detach().numpy())\n","\n","y_score = np.asarray(y_score).reshape(-1,3)\n","y_val = np.asarray(y_test).reshape(-1)\n","y_val = label_binarize(y_val, classes=[0, 1, 2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e4W2zGiNMtgj"},"source":["#### 3.2 Plotting the ROC Curve\n","\n","You may refer to this [article](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) to learn about the ROC Curve"]},{"cell_type":"code","metadata":{"id":"J8CW4sWvMnLe"},"source":["n_classes = y_val.shape[1]\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_val[:, i], y_score[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_val.ravel(), y_score.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","\n","mean_tpr = np.zeros_like(all_fpr)\n","for i in range(n_classes):\n","    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n","\n","mean_tpr /= n_classes\n","\n","fpr[\"macro\"] = all_fpr\n","tpr[\"macro\"] = mean_tpr\n","roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","plt.rcParams['figure.figsize'] = [7, 5]\n","lw = 2\n","plt.figure()\n","plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n","         label='micro-average (area = {})'\n","               ''.format(round(roc_auc[\"micro\"],5)),\n","         color='deeppink', linestyle=':', linewidth=4)\n","\n","plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n","         label='macro-average (area = {})'\n","               ''.format(round(roc_auc[\"macro\"],5)),\n","         color='navy', linestyle=':', linewidth=4)\n","\n","labels = ['no sub', 'spherical', 'vortex']\n","colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n","for i, color in zip(range(n_classes), colors):\n","    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n","             label='{} (area = {})'\n","             ''.format(labels[i], round(roc_auc[i],5)))\n","\n","# Plot the ROC \n","plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.legend(loc=\"lower right\", prop={\"size\":10})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"upF79YOrOk46"},"source":["The AUC score is very low since we have trained a basic CNN model which is chosen for the sole purpose of demonstration. We expect your model to have a high AUC score."]},{"cell_type":"markdown","metadata":{"id":"oHD8VEzyOuad"},"source":["## Submission Guidelines \n","\n","* You are required to submit a Google Colab Jupyter Notebook clearly showing your implementation along with the evaluation metrics (ROC curve, and AUC score) for the validation data.\n","* You must also submit the final trained model, including the model architecture and the trained weights ( For example: HDF5 file, .pb file, .pt file, etc. )\n","* You can use this example notebook as a template for your work. \n","\n","> **_NOTE:_**  You are free to use any ML framework such as PyTorch, Keras, TensorFlow, etc."]}]}
